{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving Data from Fitbit Web API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook used for retrieving raw data from the web api. However, Intraday data (daily detail-level response) is required for applications request which cannot process in the current moment. Thus, part of deatil data has to be mannually done on Fitbit online platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import ast\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Aceess_token (Generate using Fitbit OAuth 2.0 Tutorial)\n",
    "access_token = \"your_generate_access_token\"\n",
    "headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "\n",
    "start_date = datetime.datetime(2023, 11, 1)\n",
    "end_date = datetime.datetime(2024, 2, 15)\n",
    "\n",
    "start_date_str = start_date.strftime(\"%Y-%m-%d\")\n",
    "end_date_str = end_date.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retreivie Sleep log\n",
    "sleep_log_data = []\n",
    "\n",
    "url = f\"https://api.fitbit.com/1.2/user/-/sleep/date/{start_date_str}/{end_date_str}.json\"\n",
    "response = requests.get(url, headers=headers)\n",
    "data = response.json()\n",
    "\n",
    "sleep_log_df = pd.DataFrame(data['sleep'])\n",
    "\n",
    "# Filter the type column to keep only rows where type is 0 (Sufficient data to generate log)\n",
    "sleep_log_df = sleep_log_df[sleep_log_df['infoCode'] == 0]\n",
    "sleep_log_df = sleep_log_df[sleep_log_df['isMainSleep'] == True]\n",
    "\n",
    "sleep_log_df.drop('logId', axis=1, inplace=True)\n",
    "sleep_log_df.drop('logType', axis=1, inplace=True)\n",
    "sleep_log_df.drop('infoCode', axis=1, inplace=True)\n",
    "sleep_log_df.drop('type', axis=1, inplace=True)\n",
    "sleep_log_df.drop('isMainSleep', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sleep Summary\n",
    "sleep_summary_df = sleep_log_df\n",
    "\n",
    "sleep_summary_df.drop('levels', axis=1, inplace=True)\n",
    "sleep_summary_df['startTime'] = pd.to_datetime(sleep_summary_df['startTime'])\n",
    "sleep_summary_df['endTime'] = pd.to_datetime(sleep_summary_df['endTime'])\n",
    "sleep_summary_df['duration'] = sleep_summary_df['duration'] / (1000 * 60)\n",
    "sleep_summary_df = sleep_summary_df.rename(columns={'timeInBed': 'minutesInBed'})\n",
    "\n",
    "sleep_summary_df.drop('startTime', axis=1, inplace=True)\n",
    "sleep_summary_df.drop('endTime', axis=1, inplace=True)\n",
    "sleep_summary_df.to_csv('sleep_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sleep Detail Log\n",
    "new_rows = []\n",
    "\n",
    "for index, row in sleep_log_df.iterrows():\n",
    "    levels_dict = ast.literal_eval(row['levels'])\n",
    "    data = levels_dict['data']\n",
    "    \n",
    "    for entry in data:\n",
    "        new_row = row.copy()\n",
    "        \n",
    "        dateTime = entry['dateTime']\n",
    "        level = entry['level']\n",
    "        seconds = entry['seconds']\n",
    "        \n",
    "        new_row['dateTime'] = dateTime\n",
    "        new_row['level'] = level\n",
    "        new_row['seconds'] = seconds\n",
    "        \n",
    "        new_rows.append(new_row)\n",
    "\n",
    "detail_sleep_df = pd.DataFrame(new_rows)\n",
    "detail_sleep_df = detail_sleep_df.drop(columns='levels')\n",
    "\n",
    "columns_to_drop = ['duration', 'efficiency', 'endTime', 'minutesAfterWakeup','minutesAsleep','minutesAwake','minutesToFallAsleep', 'startTime','timeInBed','type', 'dateTime']\n",
    "\n",
    "detail_sleep_df = detail_sleep_df.drop(columns=columns_to_drop)\n",
    "\n",
    "detail_sleep_df.to_csv('sleep_detail.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Breathing rate\n",
    "breathing_rate_data = []\n",
    "\n",
    "date = start_date\n",
    "while date <= end_date:\n",
    "    date_str = date.strftime(\"%Y-%m-%d\")\n",
    "    url = f\"https://api.fitbit.com/1/user/-/br/date/{date_str}/all.json\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = response.json()\n",
    "\n",
    "    breathing_rate_data.extend(data['br'])\n",
    "\n",
    "    date += datetime.timedelta(days=1)\n",
    "\n",
    "breathing_rate_df = pd.DataFrame(breathing_rate_data)\n",
    "\n",
    "# Create new columns for each item in the 'value' column\n",
    "expanded_data = breathing_rate_df['value'].apply(pd.Series)\n",
    "\n",
    "# Concatenate the expanded columns with the original data\n",
    "breathing_data = pd.concat([breathing_rate_df['dateTime'], expanded_data], axis=1)\n",
    "\n",
    "breathing_data['deepSleepSummary'] = breathing_data['deepSleepSummary'].apply(lambda x: x['breathingRate'] if isinstance(x, dict) else x)\n",
    "breathing_data['remSleepSummary'] = breathing_data['remSleepSummary'].apply(lambda x: x['breathingRate'] if isinstance(x, dict) else x)\n",
    "breathing_data['fullSleepSummary'] = breathing_data['deepSleepSummary'].apply(lambda x: x['breathingRate'] if isinstance(x, dict) else x)\n",
    "breathing_data['lightSleepSummary'] = breathing_data['deepSleepSummary'].apply(lambda x: x['breathingRate'] if isinstance(x, dict) else x)\n",
    "\n",
    "breathing_data = breathing_data.rename(columns={'deepSleepSummary': 'deepSleep'})\n",
    "breathing_data = breathing_data.rename(columns={'remSleepSummary': 'remSleep'})\n",
    "breathing_data = breathing_data.rename(columns={'fullSleepSummary': 'fullSleep'})\n",
    "breathing_data = breathing_data.rename(columns={'lightSleepSummary': 'lightSleep'})\n",
    "\n",
    "breathing_data.to_csv('breathing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heat Rate\n",
    "dataframes = []\n",
    "\n",
    "# Generate a list of dates within the range\n",
    "dates = pd.date_range(start_date, end_date, freq='D')\n",
    "\n",
    "for date in dates:\n",
    "    # Convert the date to the desired string format\n",
    "    date_str = date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    url = f\"https://api.fitbit.com/1/user/-/activities/heart/date/{start_date_str}/1d/1min.json\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    filename = f'heart_rate_{date_str}.csv'\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "    # Append the dataframe to the list\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all the dataframes into a single dataframe\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Heart Rate\n",
    "date = \"_date_\"\n",
    "\n",
    "data = pd.read_json(f'../input/HR/{date}.json', typ='series')\n",
    "\n",
    "# Extract the last part from the dataframe\n",
    "last_part = data.iloc[-1]\n",
    "part = last_part['dataset']\n",
    "new = pd.DataFrame.from_dict(part)\n",
    "new.to_csv(f'{date}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Heart Rate to csv\n",
    "file_pattern = '../input/HR/*.csv'  # Update with your file path pattern\n",
    "\n",
    "# Get a list of CSV files matching the pattern\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each CSV file and read it into a DataFrame\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate the DataFrames into a single DataFrame\n",
    "concatenated_df = pd.concat(dfs)\n",
    "\n",
    "print(concatenated_df)\n",
    "\n",
    "# # Reset the index of the concatenated DataFrame\n",
    "# concatenated_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print(concatenated_df)\n",
    "# # concatenated_df.to_csv('hrv_202401.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heart Rate Variability\n",
    "date = 20240216\n",
    "\n",
    "data = pd.read_json(f'../input/HRV/202402/{date}.json', typ='series')\n",
    "\n",
    "# Extract the last part from the dataframe\n",
    "minutes_data = data['hrv'][0]['minutes']\n",
    "\n",
    "df = pd.DataFrame(minutes_data)\n",
    "\n",
    "# # Extract values from the \"value\" column to new columns\n",
    "df = pd.concat([df.drop(['value'], axis=1), df['value'].apply(pd.Series)], axis=1)\n",
    "\n",
    "df.to_csv(f'{date}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heart Rate Variability to csv\n",
    "file_pattern = '../input/HRV/202402/*.csv'  # Update with your file path pattern\n",
    "\n",
    "# Get a list of CSV files matching the pattern\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each CSV file and read it into a DataFrame\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate the DataFrames into a single DataFrame\n",
    "concatenated_df = pd.concat(dfs)\n",
    "\n",
    "# Reset the index of the concatenated DataFrame\n",
    "concatenated_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "concatenated_df.to_csv('hrv_202402.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat list of HRV into single training\n",
    "file_pattern = '../input/HRV/*.csv'\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "concatenated_df = pd.concat(dfs)\n",
    "concatenated_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "concatenated_df.to_csv('hrv.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat list of stress into single training\n",
    "\n",
    "file_pattern = './input/Stress/*.csv'\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "concatenated_df = pd.concat(dfs)\n",
    "concatenated_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "concatenated_df.to_csv('stress.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Steps\n",
    "# List the directory containing the JSON files\n",
    "directory = 'path_to_folder'\n",
    "\n",
    "# Initialize an empty dictionary to store the extracted data\n",
    "data_dict = {}\n",
    "\n",
    "# Iterate over each JSON file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.json'):\n",
    "        try:\n",
    "            # Read the JSON file\n",
    "            with open(os.path.join(directory, filename)) as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "            # Extract the date and total steps\n",
    "            activities = data['activities']\n",
    "            summary = data['summary']\n",
    "            if len(activities) > 0:\n",
    "                date = activities[0].get('startDate')\n",
    "                steps = summary['steps']\n",
    "\n",
    "                # Keep only the first record of each day\n",
    "                if date not in data_dict:\n",
    "                    data_dict[date] = steps\n",
    "        except (KeyError, IndexError):\n",
    "            # Skip the file if it doesn't contain the necessary fields\n",
    "            continue\n",
    "\n",
    "# Create a Pandas DataFrame from the dictionary\n",
    "df = pd.DataFrame({'date': list(data_dict.keys()), 'steps': list(data_dict.values())})\n",
    "df.to_csv('steps.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pattern = '../input/Sleep/*.csv'\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "concatenated_df = pd.concat(dfs)\n",
    "concatenated_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "concatenated_df.to_csv('sleep.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPO2\n",
    "folder_path = '../input/spo2/'\n",
    "\n",
    "json_files = [f for f in os.listdir(folder_path) if f.endswith('.json')]\n",
    "\n",
    "for json_file in json_files:\n",
    "    date = json_file.split('.')[0]  # Extract the date from the file name\n",
    "    \n",
    "    # Read the JSON file\n",
    "    data = pd.read_json(os.path.join(folder_path, json_file), typ='series')\n",
    "    \n",
    "    # Extract the last part from the dataframe\n",
    "    minutes_data = data['minutes']\n",
    "    \n",
    "    # Create a DataFrame from the minutes data\n",
    "    df = pd.DataFrame(minutes_data)\n",
    "    df = df.rename(columns={'value': 'spo2'})\n",
    "    \n",
    "    # Save the DataFrame as a CSV file\n",
    "    csv_file = f'spo2_{date}.csv'\n",
    "    df.to_csv(csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat list of HRV into single training\n",
    "file_pattern = '../input/spo2/raw/*.csv'\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "concatenated_df = pd.concat(dfs)\n",
    "concatenated_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "concatenated_df.to_csv('spo2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pattern = '../input/breathing/*.csv'\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "concatenated_df = pd.concat(dfs)\n",
    "concatenated_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "concatenated_df.to_csv('breathing.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import ast\n",
    "import glob\n",
    "\n",
    "# Temp aceess_token (Generate using Fitbit OAuth 2.0 Tutorial)\n",
    "access_token = \"eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiIyM1I5SzQiLCJzdWIiOiJCUVpTRlkiLCJpc3MiOiJGaXRiaXQiLCJ0eXAiOiJhY2Nlc3NfdG9rZW4iLCJzY29wZXMiOiJyc29jIHJlY2cgcnNldCByb3h5IHJudXQgcnBybyByc2xlIHJjZiByYWN0IHJsb2MgcnJlcyByd2VpIHJociBydGVtIiwiZXhwIjoxNzA2OTc5MzYwLCJpYXQiOjE3MDY5NTA1NjB9.N1u_a7SM1dP-QYs45VxcdAIlMn-GHueBBvL1PG1mUGU\"\n",
    "headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "\n",
    "start_date = datetime.datetime(2023, 11, 1)\n",
    "end_date = datetime.datetime(2024, 1, 10)\n",
    "\n",
    "start_date_str = start_date.strftime(\"%Y-%m-%d\")\n",
    "end_date_str = end_date.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retreivie Sleep log\n",
    "sleep_log_data = []\n",
    "\n",
    "start_date = datetime.datetime(2023, 11, 1)\n",
    "end_date = datetime.datetime(2024, 1, 31)\n",
    "\n",
    "start_date_str = start_date.strftime(\"%Y-%m-%d\")\n",
    "end_date_str = end_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "url = f\"https://api.fitbit.com/1.2/user/-/sleep/date/{start_date_str}/{end_date_str}.json\"\n",
    "response = requests.get(url, headers=headers)\n",
    "data = response.json()\n",
    "\n",
    "sleep_log_df = pd.DataFrame(data['sleep'])\n",
    "\n",
    "# Gerneral pre-procseesing the data\n",
    "# Filter the type column to keep only rows where type is 0 (Sufficient data to generate log)\n",
    "sleep_log_df = sleep_log_df[sleep_log_df['infoCode'] == 0]\n",
    "sleep_log_df = sleep_log_df[sleep_log_df['isMainSleep'] == True]\n",
    "\n",
    "sleep_log_df.drop('logId', axis=1, inplace=True)\n",
    "sleep_log_df.drop('logType', axis=1, inplace=True)\n",
    "sleep_log_df.drop('infoCode', axis=1, inplace=True)\n",
    "sleep_log_df.drop('type', axis=1, inplace=True)\n",
    "sleep_log_df.drop('isMainSleep', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sleep Summary\n",
    "sleep_summary_df = sleep_log_df\n",
    "\n",
    "sleep_log_df.drop('startTime', axis=1, inplace=True)\n",
    "sleep_log_df.drop('endTime', axis=1, inplace=True)\n",
    "\n",
    "sleep_summary_df.to_csv('sleep_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sleep Summary\n",
    "sleep_summary_df = sleep_log_df\n",
    "\n",
    "sleep_summary_df.drop('levels', axis=1, inplace=True)\n",
    "sleep_summary_df['startTime'] = pd.to_datetime(sleep_summary_df['startTime'])\n",
    "sleep_summary_df['endTime'] = pd.to_datetime(sleep_summary_df['endTime'])\n",
    "sleep_summary_df['duration'] = sleep_summary_df['duration'] / (1000 * 60)\n",
    "sleep_summary_df = sleep_summary_df.rename(columns={'timeInBed': 'minutesInBed'})\n",
    "\n",
    "sleep_summary_df.to_csv('sleep_summary_240110.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'levels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3628\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3629\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'levels'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9752\\3051907501.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msleep_log_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mlevels_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'levels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlevels_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 958\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1067\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1069\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1070\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3629\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3631\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3632\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3633\u001b[0m                 \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'levels'"
     ]
    }
   ],
   "source": [
    "# Sleep Detail Log\n",
    "new_rows = []\n",
    "\n",
    "for index, row in sleep_log_df.iterrows():\n",
    "    levels_dict = ast.literal_eval(row['levels'])\n",
    "    data = levels_dict['data']\n",
    "    \n",
    "    for entry in data:\n",
    "        new_row = row.copy()\n",
    "        \n",
    "        dateTime = entry['dateTime']\n",
    "        level = entry['level']\n",
    "        seconds = entry['seconds']\n",
    "        \n",
    "        new_row['dateTime'] = dateTime\n",
    "        new_row['level'] = level\n",
    "        new_row['seconds'] = seconds\n",
    "        \n",
    "        new_rows.append(new_row)\n",
    "\n",
    "detail_sleep_df = pd.DataFrame(new_rows)\n",
    "detail_sleep_df = detail_sleep_df.drop(columns='levels')\n",
    "\n",
    "# Define the list of columns to drop\n",
    "columns_to_drop = ['duration', 'efficiency', 'endTime', 'minutesAfterWakeup','minutesAsleep','minutesAwake','minutesToFallAsleep', 'startTime','timeInBed','type', 'dateTime']\n",
    "\n",
    "detail_sleep_df = detail_sleep_df.drop(columns=columns_to_drop)\n",
    "\n",
    "detail_sleep_df.to_csv('sleep_detail_240110.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Breathing rate\n",
    "breathing_rate_data = []\n",
    "\n",
    "start_date = datetime.datetime(2023, 11, 1)\n",
    "end_date = datetime.datetime(2024, 1, 10)\n",
    "\n",
    "date = start_date\n",
    "while date <= end_date:\n",
    "    date_str = date.strftime(\"%Y-%m-%d\")\n",
    "    url = f\"https://api.fitbit.com/1/user/-/br/date/{date_str}/all.json\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = response.json()\n",
    "\n",
    "    breathing_rate_data.extend(data['br'])\n",
    "\n",
    "    date += datetime.timedelta(days=1)\n",
    "\n",
    "breathing_rate_df = pd.DataFrame(breathing_rate_data)\n",
    "\n",
    "# Create new columns for each item in the 'value' column\n",
    "expanded_data = breathing_rate_df['value'].apply(pd.Series)\n",
    "\n",
    "# Concatenate the expanded columns with the original data\n",
    "breathing_data = pd.concat([breathing_rate_df['dateTime'], expanded_data], axis=1)\n",
    "\n",
    "breathing_data['deepSleepSummary'] = breathing_data['deepSleepSummary'].apply(lambda x: x['breathingRate'] if isinstance(x, dict) else x)\n",
    "breathing_data['remSleepSummary'] = breathing_data['remSleepSummary'].apply(lambda x: x['breathingRate'] if isinstance(x, dict) else x)\n",
    "breathing_data['fullSleepSummary'] = breathing_data['deepSleepSummary'].apply(lambda x: x['breathingRate'] if isinstance(x, dict) else x)\n",
    "breathing_data['lightSleepSummary'] = breathing_data['deepSleepSummary'].apply(lambda x: x['breathingRate'] if isinstance(x, dict) else x)\n",
    "\n",
    "breathing_data = breathing_data.rename(columns={'deepSleepSummary': 'deepSleep'})\n",
    "breathing_data = breathing_data.rename(columns={'remSleepSummary': 'remSleep'})\n",
    "breathing_data = breathing_data.rename(columns={'fullSleepSummary': 'fullSleep'})\n",
    "breathing_data = breathing_data.rename(columns={'lightSleepSummary': 'lightSleep'})\n",
    "\n",
    "breathing_data.to_csv('breathing_240110.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heat Rate Series\n",
    "hr_data = []\n",
    "\n",
    "url = f\"https://api.fitbit.com/1/user/-/activities/heart/date/{start_date_str}/{end_date_str}.json\"\n",
    "response = requests.get(url, headers=headers)\n",
    "data = response.json()\n",
    "hr_df = pd.DataFrame(data['activities-heart'])\n",
    "\n",
    "# Create new columns for each item in the 'value' column\n",
    "hr_expanded_data = hr_df['value'].apply(pd.Series)\n",
    "# Concatenate the expanded columns with the original data\n",
    "hr_df = pd.concat([hr_df['dateTime'], hr_expanded_data], axis=1)\n",
    "\n",
    "hr_df.drop('customHeartRateZones', axis=1, inplace=True)\n",
    "\n",
    "import json\n",
    "hr_detail_data = []\n",
    "\n",
    "for index, row in hr_df.iterrows():\n",
    "    zones_list = row['heartRateZones']\n",
    "    \n",
    "    for zone in zones_list:\n",
    "        new_row = row.copy()\n",
    "        \n",
    "        name = zone['name']\n",
    "        minutes = zone['minutes']\n",
    "        caloriesOut = zone['caloriesOut']\n",
    "        heartRateMin = zone['min']\n",
    "        heartRateMax = zone['max']\n",
    "        \n",
    "        new_row['name'] = name\n",
    "        new_row['minutes'] = minutes\n",
    "        new_row['caloriesOut'] = caloriesOut\n",
    "        new_row['heartRateMin'] = heartRateMin\n",
    "        new_row['heartRateMax'] = heartRateMax\n",
    "        \n",
    "        hr_detail_data.append(new_row)\n",
    "\n",
    "hr_df = pd.DataFrame(hr_detail_data)\n",
    "hr_df = hr_df.drop(columns='heartRateZones')\n",
    "\n",
    "hr_df.to_csv('hr_series_240110.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heat Rate\n",
    "dataframes = []\n",
    "\n",
    "# Generate a list of dates within the range\n",
    "dates = pd.date_range(start_date, end_date, freq='D')\n",
    "\n",
    "for date in dates:\n",
    "    # Convert the date to the desired string format\n",
    "    date_str = date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    url = f\"https://api.fitbit.com/1/user/-/activities/heart/date/{start_date_str}/1d/1min.json\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    filename = f'heart_rate_{date_str}.csv'\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "    # Append the dataframe to the list\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all the dataframes into a single dataframe\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heat Rate\n",
    "\n",
    "yesterday = datetime.datetime(2024, 1, 30)\n",
    "yesterday_str = yesterday.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "url = \"https://api.fitbit.com/1/user/-/activities/heart/date/today/1d/1min.json\"\n",
    "response = requests.get(url, headers=headers)\n",
    "data = response.json()\n",
    "print(df['categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Heart Rate\n",
    "date = 20240101\n",
    "\n",
    "data = pd.read_json(f'../input/HR/{date}.json', typ='series')\n",
    "\n",
    "# Extract the last part from the dataframe\n",
    "last_part = data.iloc[-1]\n",
    "part = last_part['dataset']\n",
    "new = pd.DataFrame.from_dict(part)\n",
    "new.to_csv(f'{date}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Heart Rate to csv\n",
    "file_pattern = '../input/HR/*.csv'  # Update with your file path pattern\n",
    "\n",
    "# Get a list of CSV files matching the pattern\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each CSV file and read it into a DataFrame\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate the DataFrames into a single DataFrame\n",
    "concatenated_df = pd.concat(dfs)\n",
    "\n",
    "print(concatenated_df)\n",
    "\n",
    "# # Reset the index of the concatenated DataFrame\n",
    "# concatenated_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print(concatenated_df)\n",
    "# # concatenated_df.to_csv('hrv_202401.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heart Rate Variability\n",
    "date = 20231130\n",
    "\n",
    "data = pd.read_json(f'../input/HRV/202311/{date}.json', typ='series')\n",
    "\n",
    "# Extract the last part from the dataframe\n",
    "minutes_data = data['hrv'][0]['minutes']\n",
    "\n",
    "df = pd.DataFrame(minutes_data)\n",
    "\n",
    "# # Extract values from the \"value\" column to new columns\n",
    "df = pd.concat([df.drop(['value'], axis=1), df['value'].apply(pd.Series)], axis=1)\n",
    "\n",
    "df.to_csv(f'{date}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heart Rate Variability to csv\n",
    "file_pattern = '../input/HRV/202311/*.csv'  # Update with your file path pattern\n",
    "\n",
    "# Get a list of CSV files matching the pattern\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each CSV file and read it into a DataFrame\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate the DataFrames into a single DataFrame\n",
    "concatenated_df = pd.concat(dfs)\n",
    "\n",
    "# Reset the index of the concatenated DataFrame\n",
    "concatenated_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "concatenated_df.to_csv('hrv_202312.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat list of HRV into single training\n",
    "file_pattern = '../input/HRV/*.csv'\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "concatenated_df = pd.concat(dfs)\n",
    "concatenated_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "concatenated_df.to_csv('hrv.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat list of stress into single training\n",
    "file_pattern = './input/Stress/*.csv'\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "concatenated_df = pd.concat(dfs)\n",
    "concatenated_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "concatenated_df.to_csv('stress.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Steps\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List the directory containing the JSON files\n",
    "directory = 'C:/Users/minni/other/FYP/ht_flask/input/steps/'\n",
    "\n",
    "# Initialize an empty dictionary to store the extracted data\n",
    "data_dict = {}\n",
    "\n",
    "# Iterate over each JSON file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.json'):\n",
    "        try:\n",
    "            # Read the JSON file\n",
    "            with open(os.path.join(directory, filename)) as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "            # Extract the date and total steps\n",
    "            activities = data['activities']\n",
    "            if len(activities) > 0:\n",
    "                date = activities[0].get('startDate')\n",
    "                steps = activities[0].get('steps')\n",
    "\n",
    "                # Keep only the first record of each day\n",
    "                if date not in data_dict:\n",
    "                    data_dict[date] = steps\n",
    "        except (KeyError, IndexError):\n",
    "            # Skip the file if it doesn't contain the necessary fields\n",
    "            continue\n",
    "\n",
    "# Create a Pandas DataFrame from the dictionary\n",
    "df = pd.DataFrame({'date': list(data_dict.keys()), 'steps': list(data_dict.values())})\n",
    "\n",
    "df.to_csv('steps.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
